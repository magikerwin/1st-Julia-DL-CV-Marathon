{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HXFxofMkAz5b"
   },
   "source": [
    "# Markdown與LaTeX簡介\n",
    "\n",
    "## Day 002 作業\n",
    "\n",
    "Sigmoid 和 tanh 是 Machine Learning 中重要且常用的激活函數 (activation function)。\n",
    "\n",
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/36f792c44c0a7069ad01386452569d6e34fe95d7)\n",
    "\n",
    "Sigmoid 函數的詳細說明，有興趣的話可以參考 [Wikipedia: Sigmoid Function](https://en.wikipedia.org/wiki/Sigmoid_function) 頁面。\n",
    "\n",
    "那，如果要用 LaTeX 撰寫上面 Sigmoid 公式的話，可以用下列的語法：\n",
    "```\n",
    "$$f(x)=\\sigma(x)=\\frac{1}{1+e^{-x}}$$\n",
    "```\n",
    "輸出公式如下：\n",
    "$$f(x)=\\sigma(x)=\\frac{1}{1+e^{-x}}$$\n",
    "\n",
    "下列是幾個重要的 LaTeX 語法簡介：\n",
    "- `\\frac` 分數，並以 `{}{}` 來放分子與分母\n",
    "- `^` 上標 (superscript)，可用在公式中的次方。若上標的字元超過1的話，也要用 `{}` 包含\n",
    "- `\\sigma` 產生 $\\sigma$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K_vKBqX2Az5y"
   },
   "source": [
    "### 題目\n",
    "\n",
    "tanh (hyperbolic tangent) 是另一個常見的激活函數，其公式如下：\n",
    "\n",
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/84c428bf21e34ccc0be8becf3443b06a4b61f3ee)\n",
    "\n",
    "請參考練習中 Sigmoid 範例，使用 LaTeX 撰寫 tanh 函數公式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sr8I--RgAz56"
   },
   "source": [
    "$$\n",
    "f(x)=tanh(x)=\\frac{(e^{x}-e^{-x})}{(e^{x}+e^{-x})}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "colab": {
   "name": "julia_002_hw.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Julia 1.4.0",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
